{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Build vocabulary\n",
      "[0/200000] tokenized the captions.\n",
      "[10000/200000] tokenized the captions.\n",
      "[20000/200000] tokenized the captions.\n",
      "[30000/200000] tokenized the captions.\n",
      "[40000/200000] tokenized the captions.\n",
      "[50000/200000] tokenized the captions.\n",
      "[60000/200000] tokenized the captions.\n",
      "[70000/200000] tokenized the captions.\n",
      "[80000/200000] tokenized the captions.\n",
      "[90000/200000] tokenized the captions.\n",
      "[100000/200000] tokenized the captions.\n",
      "[110000/200000] tokenized the captions.\n",
      "[120000/200000] tokenized the captions.\n",
      "[130000/200000] tokenized the captions.\n",
      "[140000/200000] tokenized the captions.\n",
      "[150000/200000] tokenized the captions.\n",
      "[160000/200000] tokenized the captions.\n",
      "[170000/200000] tokenized the captions.\n",
      "[180000/200000] tokenized the captions.\n",
      "[190000/200000] tokenized the captions.\n",
      "Vocabulary has 13067 words.\n",
      "Save vocabulary to feats/msr-vtt_vocab.pkl\n",
      "\n",
      "# Prepare dataset split\n",
      "\n",
      "# Convert each caption to token index list\n",
      "There are 0.220% too long captions\n",
      "Save 130240 train captions to feats/msr-vtt_captions_train.pkl.\n",
      "Save 9920 val captions to feats/msr-vtt_captions_val.pkl.\n",
      "Save 59840 test captions to feats/msr-vtt_captions_test.pkl.\n",
      "\n",
      "# Prepare ground-truth\n",
      "Preparing ground-truth...\n",
      "Created json references in results/msr-vtt_val_references.txt.json\n",
      "Created json references in results/msr-vtt_test_references.txt.json\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "'''\n",
    "准备文本相关的数据集，包括：\n",
    "1. 对数据集进行划分\n",
    "2. 把caption变成tokens\n",
    "3. 准备ground-truth\n",
    "'''\n",
    "from __future__ import print_function\n",
    "from __future__ import absolute_import\n",
    "import json\n",
    "import nltk\n",
    "import pickle\n",
    "import pprint\n",
    "import hashlib\n",
    "import sys\n",
    "from collections import Counter\n",
    "\n",
    "from args import ds\n",
    "from args import train_range, val_range, test_range\n",
    "from args import anno_json_path, vocab_pkl_path\n",
    "from args import train_caption_pkl_path, val_caption_pkl_path, test_caption_pkl_path\n",
    "from args import max_words  # 文本序列的规定长度\n",
    "from args import val_reference_txt_path, test_reference_txt_path\n",
    "#from utils import create_reference_json, build_msvd_annotation\n",
    "\n",
    "class CocoAnnotations:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.images = []\n",
    "        self.annotations = []\n",
    "        self.img_dict = {}\n",
    "        info = {\n",
    "            \"year\": 2017,\n",
    "            \"version\": '1',\n",
    "            \"description\": 'Video CaptionEval',\n",
    "            \"contributor\": 'Subhashini Venugopalan, Yangyu Chen',\n",
    "            \"url\": 'https://github.com/vsubhashini/, https://github.com/Yugnaynehc/',\n",
    "            \"date_created\": '',\n",
    "        }\n",
    "        licenses = [{\"id\": 1, \"name\": \"test\", \"url\": \"test\"}]\n",
    "        self.res = {\"info\": info,\n",
    "                    \"type\": 'captions',\n",
    "                    \"images\": self.images,\n",
    "                    \"annotations\": self.annotations,\n",
    "                    \"licenses\": licenses,\n",
    "                    }\n",
    "\n",
    "    def read_multiple_files(self, filelist):\n",
    "        for filename in filelist:\n",
    "            print('In file %s\\n' % filename)\n",
    "            self.read_file(filename)\n",
    "\n",
    "    def get_image_dict(self, img_name):\n",
    "        code = img_name.encode('utf8')\n",
    "        image_hash = int(int(hashlib.sha256(code).hexdigest(), 16) % sys.maxsize)\n",
    "        if image_hash in self.img_dict:\n",
    "            assert self.img_dict[image_hash] == img_name, 'hash colision: {0}: {1}'.format(\n",
    "                image_hash, img_name)\n",
    "        else:\n",
    "            self.img_dict[image_hash] = img_name\n",
    "        image_dict = {\"id\": image_hash,\n",
    "                      \"width\": 0,\n",
    "                      \"height\": 0,\n",
    "                      \"file_name\": img_name,\n",
    "                      \"license\": '',\n",
    "                      \"url\": img_name,\n",
    "                      \"date_captured\": '',\n",
    "                      }\n",
    "        return image_dict, image_hash\n",
    "\n",
    "    def read_file(self, filename):\n",
    "        count = 0\n",
    "        with open(filename, 'r') as opfd:\n",
    "            for line in opfd:\n",
    "                count += 1\n",
    "                id_sent = line.strip().split('\\t')\n",
    "                try:\n",
    "                    assert len(id_sent) == 2\n",
    "                    sent = id_sent[1]\n",
    "                except Exception as e:\n",
    "                    # print(line)\n",
    "                    continue\n",
    "                image_dict, image_hash = self.get_image_dict(id_sent[0])\n",
    "                self.images.append(image_dict)\n",
    "\n",
    "                self.annotations.append({\n",
    "                    \"id\": len(self.annotations) + 1,\n",
    "                    \"image_id\": image_hash,\n",
    "                    \"caption\": sent,\n",
    "                })\n",
    "\n",
    "    def dump_json(self, outfile):\n",
    "        self.res[\"images\"] = self.images\n",
    "        self.res[\"annotations\"] = self.annotations\n",
    "        with open(outfile, 'w') as fd:\n",
    "            json.dump(self.res, fd, ensure_ascii=False, sort_keys=True,\n",
    "                      indent=2, separators=(',', ': '))\n",
    "\n",
    "            \n",
    "def create_reference_json(reference_txt_path):\n",
    "    output_file = '{0}.json'.format(reference_txt_path)\n",
    "    crf = CocoAnnotations()\n",
    "    crf.read_file(reference_txt_path)\n",
    "    crf.dump_json(output_file)\n",
    "    print('Created json references in %s' % output_file)\n",
    "    \n",
    "class Vocabulary(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.word2idx = {}\n",
    "        self.idx2word = []\n",
    "        self.nwords = 0\n",
    "        self.add_word('<pad>')\n",
    "        self.add_word('<start>')\n",
    "        self.add_word('<end>')\n",
    "        self.add_word('<unk>')\n",
    "\n",
    "    def add_word(self, w):\n",
    "        '''\n",
    "        将新单词加入词汇表中\n",
    "        '''\n",
    "        if w not in self.word2idx:\n",
    "            self.word2idx[w] = self.nwords\n",
    "            self.idx2word.append(w)\n",
    "            self.nwords += 1\n",
    "\n",
    "    def __call__(self, w):\n",
    "        '''\n",
    "        返回单词对应的id\n",
    "        '''\n",
    "        if w not in self.word2idx:\n",
    "            return self.word2idx['<unk>']\n",
    "        return self.word2idx[w]\n",
    "\n",
    "    def __len__(self):\n",
    "        '''\n",
    "        得到词汇表中词汇的数量\n",
    "        '''\n",
    "        return self.nwords\n",
    "\n",
    "\n",
    "def prepare_vocab(sentences):\n",
    "    '''\n",
    "    根据标注的文本得到词汇表。频数低于threshold的单词将会被略去\n",
    "    '''\n",
    "    counter = Counter()\n",
    "    ncaptions = len(sentences)\n",
    "    for i, row in enumerate(sentences):\n",
    "        caption = row['caption']\n",
    "        # 直接按照空格进行单词的切分\n",
    "        # tokens = caption.lower().split(' ')\n",
    "        # 使用nltk来进行单词切分\n",
    "        tokens = nltk.tokenize.word_tokenize(caption.lower())\n",
    "        counter.update(tokens)\n",
    "        if i % 10000 == 0:\n",
    "            print('[{}/{}] tokenized the captions.'.format(i, ncaptions))\n",
    "\n",
    "    # 略去一些低频词\n",
    "    threshold = 3\n",
    "    words = [w for w, c in counter.items() if c >= threshold]\n",
    "    # 开始构建词典！\n",
    "    vocab = Vocabulary()\n",
    "    for w in words:\n",
    "        vocab.add_word(w)\n",
    "\n",
    "    print('Vocabulary has %d words.' % len(vocab))\n",
    "    with open(vocab_pkl_path, 'wb') as f:\n",
    "        pickle.dump(vocab, f)\n",
    "    print('Save vocabulary to %s' % vocab_pkl_path)\n",
    "    return vocab\n",
    "\n",
    "\n",
    "def prepare_split():\n",
    "    '''\n",
    "    为数据集生成train，val，test的划分。MSVD数据集可以根据Vsubhashini的划分：\n",
    "    train:1-1200, val:1201-1300, test:1301-1970\n",
    "    '''\n",
    "    split_dict = {}\n",
    "\n",
    "    for i in range(*train_range):\n",
    "        split_dict[i] = 'train'\n",
    "    for i in range(*val_range):\n",
    "        split_dict[i] = 'val'\n",
    "    for i in range(*test_range):\n",
    "        split_dict[i] = 'test'\n",
    "\n",
    "    # pprint.pprint(split_dict)\n",
    "\n",
    "    return split_dict\n",
    "\n",
    "\n",
    "def prepare_caption(vocab, split_dict, anno_data):\n",
    "    '''\n",
    "    把caption转换成token index表示然后存到picke中\n",
    "    读取存储文本标注信息的json文件，\n",
    "    并且将每一条caption以及它对应的video的id保存起来，\n",
    "    放回caption word_id list和video_id list\n",
    "    '''\n",
    "    # 初始化数据存储字典\n",
    "    captions = {'train': [], 'val': [], 'test': []}\n",
    "    lengths = {'train': [], 'val': [], 'test': []}\n",
    "    video_ids = {'train': [], 'val': [], 'test': []}\n",
    "\n",
    "    count = 0\n",
    "    for row in anno_data:\n",
    "        caption = row['caption'].lower()\n",
    "        video_id = int(row['video_id'][5:])\n",
    "        if video_id in split_dict:\n",
    "            split = split_dict[video_id]\n",
    "        else:\n",
    "            # 如果video_id不在split_dict中\n",
    "            # 那么就默认它是test\n",
    "            # 这样方便我修改split来做一些过拟合训练\n",
    "            split = 'test'\n",
    "        words = nltk.tokenize.word_tokenize(caption)\n",
    "        l = len(words) + 1  # 加上一个<end>\n",
    "        lengths[split].append(l)\n",
    "        if l > max_words:\n",
    "            # 如果caption长度超出了规定的长度，就做截断处理\n",
    "            words = words[:max_words - 1]  # 最后要留一个位置给<end>\n",
    "            count += 1\n",
    "        # 把caption用word id来表示\n",
    "        tokens = []\n",
    "        for word in words:\n",
    "            tokens.append(vocab(word))\n",
    "        tokens.append(vocab('<end>'))\n",
    "        while l < max_words:\n",
    "            # 如果caption的长度少于规定的长度，就用<pad>（0）补齐\n",
    "            tokens.append(vocab('<pad>'))\n",
    "            l += 1\n",
    "        #captions[split].append(torch.LongTensor(tokens))\n",
    "        captions[split].append(tokens)\n",
    "        video_ids[split].append(video_id)\n",
    "\n",
    "    # 统计一下有多少的caption长度过长\n",
    "    print('There are %.3f%% too long captions' % (100 * float(count) / len(anno_data)))\n",
    "\n",
    "    # 分别对train val test这三个划分进行存储\n",
    "    with open(train_caption_pkl_path, 'wb') as f:\n",
    "        pickle.dump([captions['train'], lengths['train'], video_ids['train']], f)\n",
    "        print('Save %d train captions to %s.' % (len(captions['train']),\n",
    "                                                 train_caption_pkl_path))\n",
    "    with open(val_caption_pkl_path, 'wb') as f:\n",
    "        pickle.dump([captions['val'], lengths['val'], video_ids['val']], f)\n",
    "        print('Save %d val captions to %s.' % (len(captions['val']),\n",
    "                                               val_caption_pkl_path))\n",
    "    with open(test_caption_pkl_path, 'wb') as f:\n",
    "        pickle.dump([captions['test'], lengths['test'], video_ids['test']], f)\n",
    "        print('Save %d test captions to %s.' % (len(captions['test']),\n",
    "                                                test_caption_pkl_path))\n",
    "\n",
    "\n",
    "def prepare_gt(anno_data):\n",
    "    '''\n",
    "    准备ground-truth,用来评估结果的好坏\n",
    "    '''\n",
    "    print('Preparing ground-truth...')\n",
    "    val_reference_txt = open(val_reference_txt_path, 'w')\n",
    "    test_reference_txt = open(test_reference_txt_path, 'w')\n",
    "\n",
    "    val_selected_range = range(*val_range)\n",
    "    test_selected_range = range(*test_range)\n",
    "    error_count = 0\n",
    "\n",
    "    for row in anno_data:\n",
    "        caption = row['caption'].lower()\n",
    "        video_id = int(row['video_id'][5:])\n",
    "        gt = '%d\\t%s\\n' % (video_id, caption)\n",
    "        try:\n",
    "            if video_id in val_selected_range:\n",
    "                val_reference_txt.write(gt)\n",
    "            elif video_id in test_selected_range:\n",
    "                test_reference_txt.write(gt)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(gt)\n",
    "            error_count += 1\n",
    "\n",
    "    if error_count > 0:\n",
    "        print('Error count: %d\\t' % error_count, end='')\n",
    "\n",
    "    val_reference_txt.close()\n",
    "    test_reference_txt.close()\n",
    "\n",
    "    create_reference_json(val_reference_txt_path)\n",
    "    create_reference_json(test_reference_txt_path)\n",
    "    print('done!')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    if ds == 'msvd':\n",
    "        # 以MSR-VTT数据集的格式生成MSVD数据集的标注\n",
    "        print('# Build MSVD dataset annotations:')\n",
    "        build_msvd_annotation()\n",
    "\n",
    "    # 读取json文件\n",
    "    with open(anno_json_path, 'r') as f:\n",
    "        anno_json = json.load(f)\n",
    "    anno_data = anno_json['sentences']\n",
    "\n",
    "    print('\\n# Build vocabulary')\n",
    "    vocab = prepare_vocab(anno_data)\n",
    "\n",
    "    print('\\n# Prepare dataset split')\n",
    "    split_dict = prepare_split()\n",
    "\n",
    "    print('\\n# Convert each caption to token index list')\n",
    "    prepare_caption(vocab, split_dict, anno_data)\n",
    "\n",
    "    print('\\n# Prepare ground-truth')\n",
    "    prepare_gt(anno_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
