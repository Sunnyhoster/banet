{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "from __future__ import absolute_import\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import h5py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import skimage\n",
    "from model import AppearanceEncoder, MotionEncoder\n",
    "from args import video_root, video_sort_lambda\n",
    "from args import feature_h5_path, feature_h5_feats, feature_h5_lens\n",
    "from args import max_frames, feature_size, clip_num\n",
    "import sys\n",
    "import inspect\n",
    "sys.path.append(\"..\")\n",
    "from util.preprocess import VideoC3DExtractor\n",
    "from util.preprocess import VideoResExtractor\n",
    "import tensorflow as tf\n",
    "from util.c3d import c3d\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#aencoder, mencoder\n",
    "def sample_frames(video_path, train=True):\n",
    "    '''\n",
    "    对视频帧进行采样，减少计算量。等间隔地取max_frames帧\n",
    "    '''\n",
    "#     max_frames = 60\n",
    "    frames = []\n",
    "    frame_count = 0\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if ret is False:\n",
    "            break\n",
    "        a=frame\n",
    "        frame = frame[:, :, ::-1]         #???????????????\n",
    "        b=frame\n",
    "        frames.append(frame)\n",
    "        frame_count += 1\n",
    "    if frames == []:\n",
    "        print(\"can not open %s\", video_path)\n",
    "    \n",
    "    indices = np.linspace(8, frame_count - 7, max_frames, endpoint=False, dtype=int)\n",
    "\n",
    "    frames = np.array(frames)\n",
    "    frame_list = frames[indices]\n",
    "    clip_list = []\n",
    "    for index in indices:\n",
    "        clip_list.append(frames[index - 8: index + 8])\n",
    "    clip_list = np.array(clip_list)\n",
    "    return frame_list, clip_list, frame_count\n",
    "\n",
    "\n",
    "def resize_frame(image, target_height=224, target_width=224):\n",
    "    if len(image.shape) == 2:\n",
    "        # 把单通道的灰度图复制三遍变成三通道的图片\n",
    "        image = np.tile(image[:, :, None], 3)\n",
    "    elif len(image.shape) == 4:\n",
    "        image = image[:, :, :, 0]\n",
    "\n",
    "    height, width, channels = image.shape\n",
    "    if height == width:\n",
    "        resized_image = cv2.resize(image, (target_height, target_width))\n",
    "    elif height < width:\n",
    "        resized_image = cv2.resize(image, (int(width * target_height / height),\n",
    "                                           target_width))\n",
    "        cropping_length = int((resized_image.shape[1] - target_height) / 2)\n",
    "        resized_image = resized_image[:,\n",
    "                                      cropping_length:resized_image.shape[1] - cropping_length]\n",
    "    else:\n",
    "        resized_image = cv2.resize(image, (target_height,\n",
    "                                           int(height * target_width / width)))\n",
    "        cropping_length = int((resized_image.shape[0] - target_width) / 2)\n",
    "        resized_image = resized_image[cropping_length:\n",
    "                                      resized_image.shape[0] - cropping_length]\n",
    "    return cv2.resize(resized_image, (target_height, target_width))\n",
    "\n",
    "\n",
    "def preprocess_frame(image, target_height=224, target_width=224):\n",
    "    image = resize_frame(image, target_height, target_width)\n",
    "    image = skimage.img_as_float(image).astype(np.float32)\n",
    "    # 根据在ILSVRC数据集上的图像的均值（RGB格式）进行白化\n",
    "    image -= np.array([0.485, 0.456, 0.406])\n",
    "    image /= np.array([0.229, 0.224, 0.225])\n",
    "    return image\n",
    "\n",
    "\n",
    "def extract_features():\n",
    "    # 读取视频列表，让视频按照id升序排列\n",
    "    videos = sorted(os.listdir(video_root), key=video_sort_lambda)\n",
    "    nvideos = len(videos)\n",
    "\n",
    "    # 创建保存视频特征的hdf5文件\n",
    "    if os.path.exists(feature_h5_path):\n",
    "        # 如果hdf5文件已经存在，说明之前处理过，或许是没有完全处理完\n",
    "        # 使用r+ (read and write)模式读取，以免覆盖掉之前保存好的数据\n",
    "        h5 = h5py.File(feature_h5_path, 'r+')\n",
    "        dataset_feats = h5[feature_h5_feats]\n",
    "        dataset_lens = h5[feature_h5_lens]\n",
    "    else:\n",
    "        h5 = h5py.File(feature_h5_path, 'w')\n",
    "        dataset_feats = h5.create_dataset(feature_h5_feats,\n",
    "                                          (nvideos, max_frames, feature_size),\n",
    "                                          dtype='float32')\n",
    "        dataset_lens = h5.create_dataset(feature_h5_lens, (nvideos,), dtype='int')\n",
    "\n",
    "    for i, video in enumerate(videos):\n",
    "        print(video, end=' ')\n",
    "        video_path = os.path.join(video_root, video)\n",
    "        # 提取视频帧以及视频小块\n",
    "        frame_list, clip_list, frame_count = sample_frames(video_path, train=True)\n",
    "        print(frame_count)\n",
    "\n",
    "        # 把图像做一下处理，然后转换成（batch, channel, height, width）的格式\n",
    "        frame_list = np.array([preprocess_frame(x) for x in frame_list])\n",
    "#         frame_list = frame_list.transpose((0, 3, 1, 2))\n",
    "#         frame_list = Variable(torch.from_numpy(frame_list), volatile=True).cuda()\n",
    "\n",
    "        # 视频特征的shape是max_frames x (2048 + 4096)\n",
    "        # 如果帧的数量小于max_frames，则剩余的部分用0补足\n",
    "        feats = np.zeros((max_frames, feature_size), dtype='float32')\n",
    "\n",
    "        # 先提取表观特征\n",
    "        af = extract_res(frame_list)\n",
    "\n",
    "        # 再提取动作特征\n",
    "        clip_list = np.array([[resize_frame(x, 112, 112)\n",
    "                               for x in clip] for clip in clip_list])\n",
    "#         clip_list = clip_list.transpose(0, 4, 1, 2, 3).astype(np.float32)\n",
    "#         clip_list = Variable(torch.from_numpy(clip_list), volatile=True).cuda()\n",
    "        mf = extract_c3d(clip_list)\n",
    "        \n",
    "        # 合并表观和动作特征\n",
    "        #feats[:frame_count, :] = torch.cat([af, mf], dim=1).data.cpu().numpy()\n",
    "        feats[:frame_count, :] =  tf.concat([af, mf], 1)\n",
    "        dataset_feats[i] = feats\n",
    "        dataset_lens[i] = frame_count\n",
    "\n",
    "def extract_c3d(frame_list):\n",
    "    \"\"\"Extract c3d features.\"\"\"\n",
    "    # Session config.\n",
    "    sess_config = tf.ConfigProto()\n",
    "    sess_config.gpu_options.allow_growth = True\n",
    "    sess_config.gpu_options.visible_device_list = '0'\n",
    "\n",
    "    with tf.Graph().as_default(), tf.Session(config=sess_config) as sess:\n",
    "        extractor = VideoC3DExtractor(max_frames, sess)\n",
    "        c3d_features = extractor.extract(frame_list)\n",
    "        \n",
    "    return c3d_features\n",
    "\n",
    "def extract_res(clip_list):\n",
    "    \"\"\"Extract res features.\"\"\"\n",
    "    # Session config.\n",
    "    sess_config = tf.ConfigProto()\n",
    "    sess_config.gpu_options.allow_growth = True\n",
    "    sess_config.gpu_options.visible_device_list = '0'\n",
    "\n",
    "    with tf.Graph().as_default(), tf.Session(config=sess_config) as sess:\n",
    "        extractor = VideoResExtractor(max_frames, sess)\n",
    "        res_features = extractor.extract(video_path)\n",
    "        \n",
    "    return res_features\n",
    "\n",
    "\n",
    "def main():\n",
    "#     aencoder = VideoC3DExtractor()\n",
    "#     aencoder.eval()\n",
    "#     aencoder.cuda()\n",
    "\n",
    "#     mencoder = VideoResExtractor\n",
    "#     mencoder.eval()\n",
    "#     mencoder.cuda()\n",
    "\n",
    "    extract_features()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = VideoResExtractor(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess_config = tf.ConfigProto()\n",
    "sess_config.gpu_options.allow_growth = True\n",
    "sess_config.gpu_options.visible_device_list = '0'\n",
    "    \n",
    "with tf.Graph().as_default(), tf.Session(config=sess_config) as sess:\n",
    "    extractor = VideoResExtractor(max_frames, sess)\n",
    "    res_features = extractor.extract(video_path)\n",
    "#     tf.placeholder(tf.float32, [20, 16, 112, 112, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.placeholder(tf.float32, [20, 16, 112, 112, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.placeholder"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
